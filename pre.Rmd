---
title: "Computational Imaging Presentation"
author: "Zhengyang Fang"
date: "May 4, 2019"
output: slidy_presentation
---

## Motivation

- Example: Deblurring -> denoising

$y$: observation. $x$: the "truth". $A$: forward transform.

$$
\hat x =\arg \min_x\|y-Ax\|_2^2-\tau\|x\|_{TV}.
$$

Solve by proximal gradient method:

Step 1.
$$
\tilde x=x^{(k)}-t_kA^T(y-Ax^{(k)}).
$$
Step 2. Solve
$$
x^{(k+1)}=\arg\min_x \frac12\|x-\tilde x\|_2^2+t_k\tau\|x\|_{TV}.
$$

- Motivation

    + Generalize those two terms

    + Use ADMM instead of proximal gradient method

    + Plug-and-play: apply *(any)* denoising algorithm



## Algorithm

- Intro to ADMM

    + dual descent
    + Multiplier method 
    + ADMM

- MAP framework

$$
\max_x f(x|y)\propto f(y|x)f(x),
$$
which is equivalent to maximize
$$
\max_x \log(y|x)+\log(x)=l(y;x)+\beta \cdot s(x)
$$

## Algorithm

- Framework in this paper

Solve
$$
\begin{aligned}
(\hat x,\hat v)=~&\arg\max_{x,v}\{l(y;x)+\beta\cdot s(v)\},\\
&s.t.~x=v.
\end{aligned}
$$

$l(y;x)$: the forward transform.

$\beta\cdot s(v)$: the prior.

Algorithm:

> repeat until converge:
$$
\begin{aligned}
&\hat x\leftarrow \arg\min_x\left\{l(y;x)+\frac\lambda 2\|x-(\hat v-u)\|_2^2\right\},\\
&\hat v\leftarrow \arg\min_v\left\{\frac \lambda 2\|v-(\hat x +u)\|^2_2+\beta s(v)\right\},\\
&v\leftarrow u+(\hat x-\hat v).
\end{aligned}
$$


## Experiment and recent work (optional)

optional

