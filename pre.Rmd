---
title: "Plug and Play Priors for Model Based Reconstruction"
author: "Zhengyang Fang, Jin Li"
date: "May 8, 2019"
output: slidy_presentation
---

## Motivation

- In class, we had an image reconstruction problem: 

$y$: observation. $x$: the "truth". $A$: forward transform.

$$
\hat x =\min_x\|y-Ax\|_2^2-\tau\|x\|_{TV}.
$$

Solve by proximal gradient method:

Step 1: Gradient Step:
$$
\tilde x=x^{(k)}-t_kA^T(y-Ax^{(k)}).
$$
Step 2: Solve:
$$
x^{(k+1)}=\arg\min_x \frac12\|x-\tilde x\|_2^2+t_k\tau\|x\|_{TV}.
$$

- Plug-and-play

## Why the Plug and Play Model Is Important


- In the previous slide, solving the forward (the forwards transform) plus prior (the denoising part) model is specific to the problem

- It is sub optimal to create a new algorithm every time we have a different combination of a forward and prior model

- The goal of the Plug-and-Play Priors for model reconstruction aims to solve that issue


## Brief Background 

- There has been great progress in improving forward models and denoising algorithms, but little progress has been made to cleanly integrate those two steps

- There has been attempts (ex. BM3D) to incorporate advanced priors with general inverse problems, but is not general enough

## What the Model Provides



- this model provides the flexibility to combine state of the art forward models with state of the art denoising models

- allows us to use denoising methods that are not explicitly formulated as an optimization problem

- simplifies software integration by decoupling the prior and forwards model terms

## Algorithm

- Intro to ADMM
- MAP framework

## Experiment and recent work (optional)

optional

